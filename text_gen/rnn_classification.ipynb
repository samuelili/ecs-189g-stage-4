{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T02:57:45.438722Z",
     "start_time": "2025-05-23T02:57:45.424219Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# define import\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ],
   "id": "1c0236cb2c248c6e",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Data Loading Pre-processing",
   "id": "a258d92701d9161e"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-23T02:57:47.290226Z",
     "start_time": "2025-05-23T02:57:46.242865Z"
    }
   },
   "source": [
    "import pickle\n",
    "import random\n",
    "\n",
    "with open(\"text_classification_train_words\", \"rb\") as f:\n",
    "    train = pickle.load(f)\n",
    "\n",
    "with open(\"text_classification_test_words\", \"rb\") as f:\n",
    "    test = pickle.load(f)\n",
    "\n",
    "print(f\"{len(train)} samples in train\")\n",
    "print(f\"{train[random.randint(0, len(train) - 1)]}\")\n",
    "print(f\"{len(test)} samples in test\")\n",
    "print(f\"{test[random.randint(0, len(test) - 1)]}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 samples in train\n",
      "{'id': '3060', 'rating': 1, 'label': 0, 'text': \"This has to be creepiest, most twisted holiday film that I've ever clapped eyes on, and that's saying something. I know that the Mexican people have some odd ideas about religion, mixing up ancient Aztec beliefs with traditional Christian theology. But their Day of the Dead isn't half as scary as their take on Santa Claus.<br /><br />So..Santa isn't some jolly, fat red-suited alcoholic(take a look at those rosy cheeks sometime!). Rather, he's a skinny sociopathic pedophile living in Heaven(or the heavens, whichever), with a bunch of kids who work harder than the one's in Kathy Lee Gifford's sweat shops. They sing oh-so-cute traditional songs of their homelands while wearing clothing so stereotypical that i was surprised there wasn't a little African-American boy in black face singing 'Mammy'. This Santa is a Peeping Tom pervert who watches and listens to everything that everybody does from his 'eye in the sky'. This is so he can tell who's been naughty or nice(with an emphasis on those who are naughty, I'd bet).<br /><br />There's no Mrs. Claus, no elves(what does he need elves for when he's got child labor?) and the reindeer are mechanical wind-up toys! This floating freak show hovers on a cloud, presumably held up by its silver lining.<br /><br />Santa's nemesis is...the Devil?! What is this, Santa our Lord and Savior? Weird. Anyhoo, Satan sends one of his minions, a mincing, prancing devil named Pitch, to try to screw up Christmas. Let me get this straight-the forces of purest evil are trying to ruin a completely commercial and greed driven holiday? Seems kind of redundant, doesn't it?<br /><br />Pitch is totally ineffectual. He tries to talk some children into being bad, but doesn't have much luck. I was strongly struck by the storyline of the saintly little girl Lupe, who's family is very poor. All that she wants is a doll for Christmas, but he parents can't afford to buy her one(they spent all of their money on the cardboard that they built their house out of). So Pitch tries to encourage her to steal a doll. In reality, that's the only way that a girl that poor would ever get a doll, because being saintly and praying to God and holy Santa doesn't really work. But Lupe resists temptation and tells Pitch to get thee behind her, and so is rewarded by being given a doll so creepy looking that you just know that it's Chucky's sister.<br /><br />Along the way Pitch manages to get Santa stuck in a tree(uh-huh) from whence he's rescued by Merlin! Merlin? You have got to be kidding me! Since when do mythical Druidic figures appear in Christmas tales, or have anything to do with a Christian religion? And doesn't God disapprove of magic? They'd have been burning Merlin at the stake a few hundred years ago, not asking him to come to the rescue of one of God's Aspects(or that's what I assume Santa must be, to be going up against Satan). This movie is one long HUH? from start to finish, and it'll make you wonder if that eggnog you drank wasn't spiked or something. Probably it was, since this movie is like one long giant DT.\", 'words': ['creepiest', 'twisted', 'holiday', 'film', 'ever', 'clapped', 'eyes', 'saying', 'something', 'know', 'mexican', 'people', 'odd', 'ideas', 'religion', 'mixing', 'ancient', 'aztec', 'beliefs', 'traditional', 'christian', 'theology', 'day', 'dead', 'nt', 'half', 'scary', 'take', 'santa', 'claus', 'br', 'br', 'santa', 'nt', 'jolly', 'fat', 'redsuited', 'alcoholic', 'take', 'look', 'rosy', 'cheeks', 'sometime', 'rather', 'skinny', 'sociopathic', 'pedophile', 'living', 'heaven', 'heavens', 'whichever', 'bunch', 'kids', 'work', 'harder', 'one', 'kathy', 'lee', 'gifford', 'sweat', 'shops', 'sing', 'ohsocute', 'traditional', 'songs', 'homelands', 'wearing', 'clothing', 'stereotypical', 'surprised', 'nt', 'little', 'africanamerican', 'boy', 'black', 'face', 'singing', 'mammy', 'santa', 'peeping', 'tom', 'pervert', 'watches', 'listens', 'everything', 'everybody', 'eye', 'sky', 'tell', 'naughty', 'nice', 'emphasis', 'naughty', 'bet', 'br', 'br', 'mrs', 'claus', 'elves', 'need', 'elves', 'got', 'child', 'labor', 'reindeer', 'mechanical', 'windup', 'toys', 'floating', 'freak', 'show', 'hovers', 'cloud', 'presumably', 'held', 'silver', 'lining', 'br', 'br', 'santa', 'nemesis', 'devil', 'santa', 'lord', 'savior', 'weird', 'anyhoo', 'satan', 'sends', 'one', 'minions', 'mincing', 'prancing', 'devil', 'named', 'pitch', 'try', 'screw', 'christmas', 'let', 'get', 'straightthe', 'forces', 'purest', 'evil', 'trying', 'ruin', 'completely', 'commercial', 'greed', 'driven', 'holiday', 'seems', 'kind', 'redundant', 'nt', 'br', 'br', 'pitch', 'totally', 'ineffectual', 'tries', 'talk', 'children', 'bad', 'nt', 'much', 'luck', 'strongly', 'struck', 'storyline', 'saintly', 'little', 'girl', 'lupe', 'family', 'poor', 'wants', 'doll', 'christmas', 'parents', 'ca', 'nt', 'afford', 'buy', 'one', 'spent', 'money', 'cardboard', 'built', 'house', 'pitch', 'tries', 'encourage', 'steal', 'doll', 'reality', 'way', 'girl', 'poor', 'would', 'ever', 'get', 'doll', 'saintly', 'praying', 'god', 'holy', 'santa', 'nt', 'really', 'work', 'lupe', 'resists', 'temptation', 'tells', 'pitch', 'get', 'thee', 'behind', 'rewarded', 'given', 'doll', 'creepy', 'looking', 'know', 'chucky', 'sister', 'br', 'br', 'along', 'way', 'pitch', 'manages', 'get', 'santa', 'stuck', 'tree', 'uhhuh', 'whence', 'rescued', 'merlin', 'merlin', 'got', 'kidding', 'since', 'mythical', 'druidic', 'figures', 'appear', 'christmas', 'tales', 'anything', 'christian', 'religion', 'nt', 'god', 'disapprove', 'magic', 'burning', 'merlin', 'stake', 'hundred', 'years', 'ago', 'asking', 'come', 'rescue', 'one', 'god', 'aspects', 'assume', 'santa', 'must', 'going', 'satan', 'movie', 'one', 'long', 'huh', 'start', 'finish', 'make', 'wonder', 'eggnog', 'drank', 'nt', 'spiked', 'something', 'probably', 'since', 'movie', 'like', 'one', 'long', 'giant', 'dt']}\n",
      "25000 samples in test\n",
      "{'id': '10895', 'rating': 1, 'label': 0, 'text': \"This movie has got to be the biggest disappointment I've ever experienced with a film. The acting is horrific, the suspense build up minimal, and the plot overall is ridiculous. I found myself rooting for the victim to just hurry up and become a victim, because she obviously needed to be put out of her misery. Anyone with rudimentary knowledge of how the world works will immediately be disgusted at the leaps we're asked to make in logic, and the so-called suspenseful buildup would be lucky to get a 3 year old to be mildly worried. I'm dismayed that a sequel is planned, because it means they'll be asking us to once again swallow a sub par plot line. If this is an example of Raw Feed's work, I think I'll be avoiding any and all future films by them.\", 'words': ['movie', 'got', 'biggest', 'disappointment', 'ever', 'experienced', 'film', 'acting', 'horrific', 'suspense', 'build', 'minimal', 'plot', 'overall', 'ridiculous', 'found', 'rooting', 'victim', 'hurry', 'become', 'victim', 'obviously', 'needed', 'put', 'misery', 'anyone', 'rudimentary', 'knowledge', 'world', 'works', 'immediately', 'disgusted', 'leaps', 'asked', 'make', 'logic', 'socalled', 'suspenseful', 'buildup', 'would', 'lucky', 'get', 'year', 'old', 'mildly', 'worried', 'dismayed', 'sequel', 'planned', 'means', 'asking', 'us', 'swallow', 'sub', 'par', 'plot', 'line', 'example', 'raw', 'feed', 'work', 'think', 'avoiding', 'future', 'films']}\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T02:57:48.715556Z",
     "start_time": "2025-05-23T02:57:47.711770Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# get vocab size\n",
    "vocab = set()\n",
    "i = 0\n",
    "for sample in train + test:\n",
    "    for word in sample['words']:\n",
    "        vocab.add(word)\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "print(f\"Found a vocab size of {vocab_size}\")"
   ],
   "id": "f61adfab216d51ba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a vocab size of 133264\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Prepare to be embeddings",
   "id": "422f662087b7a7aa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T02:57:49.209999Z",
     "start_time": "2025-05-23T02:57:49.147769Z"
    }
   },
   "cell_type": "code",
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "word_to_ix = {}\n",
    "\n",
    "for i, word in enumerate(vocab):\n",
    "    word_to_ix[word] = i"
   ],
   "id": "d43f1d11acce111c",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "##  Split Training Data",
   "id": "65934447f34331d2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T02:58:19.071722Z",
     "start_time": "2025-05-23T02:57:50.388231Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_dataset(dataset):\n",
    "    X, Y = [], []\n",
    "    for data in dataset:\n",
    "        embeddings = torch.tensor([torch.tensor([word_to_ix[word]], dtype=torch.long) for word in data['words']])\n",
    "        X.append(embeddings)\n",
    "        Y.append(data['label'])\n",
    "\n",
    "    return pad_sequence(X, batch_first=True), torch.tensor(Y)\n",
    "\n",
    "\n",
    "X_train, Y_train = create_dataset(train)\n",
    "X_test, Y_test = create_dataset(test)"
   ],
   "id": "18407271bb55f5eb",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Prepare For Training",
   "id": "d7e29aaf5421f085"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T02:57:43.393955Z",
     "start_time": "2025-05-23T02:57:43.336425Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"using device: {device}\")"
   ],
   "id": "beccbd9c58e6f651",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T03:08:16.272948Z",
     "start_time": "2025-05-23T03:08:16.263053Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# define our model class\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        out, _ = self.rnn(x)\n",
    "        out = self.fc(out[:, -1, :])  # Get output from the last time step\n",
    "        return out"
   ],
   "id": "e2323b225572426c",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T03:08:17.360296Z",
     "start_time": "2025-05-23T03:08:17.181673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "embedding_dim = 64  # tunable\n",
    "hidden_size = 128  # tunable\n",
    "output_size = 1 # binary classification\n",
    "learning_rate = 0.001\n",
    "sequence_length = 100  # Length of input sequences\n",
    "epochs = 2  # Number of epochs\n",
    "\n",
    "# Instantiate the model\n",
    "model = RNN(vocab_size, embedding_dim, hidden_size, output_size).to(device)\n",
    "train_data = torch.utils.data.TensorDataset(X_train, Y_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "\n",
    "val_data = torch.utils.data.TensorDataset(X_test, Y_test)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=64, shuffle=False)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss_epoch = 0\n",
    "    num_batches = len(train_loader)\n",
    "    for i, (batch_X, batch_y) in enumerate(train_loader):\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss_epoch += loss.item()\n",
    "        print(f\"Batch [{i}/{num_batches}]\\r\", end=\"\")\n",
    "    avg_train_loss = train_loss_epoch / len(train_loader)\n",
    "    print(f'Epoch [{epoch + 1}/{epochs}], Training Loss: {avg_train_loss:.4f}\\r')\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_X_val, batch_y_val in val_loader:\n",
    "            batch_X_val, batch_y_val = batch_X_val.to(device), batch_y_val.to(device) # Uncomment if using GPU\n",
    "            outputs_val = model(batch_X_val)\n",
    "            loss_val = criterion(outputs_val, batch_y_val)\n",
    "            val_loss += loss_val.item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    print(f'Epoch [{epoch + 1}/{epochs}], Validation Loss: {avg_val_loss:.4f}')\n",
    "\n",
    "print(\"Training complete.\")"
   ],
   "id": "14db5d657b1d5f4",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[23], line 9\u001B[0m\n\u001B[0;32m      6\u001B[0m epochs \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2\u001B[39m  \u001B[38;5;66;03m# Number of epochs\u001B[39;00m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;66;03m# Instantiate the model\u001B[39;00m\n\u001B[1;32m----> 9\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mRNN\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvocab_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43membedding_dim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhidden_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_size\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     10\u001B[0m train_data \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mTensorDataset(X_train, Y_train)\n\u001B[0;32m     11\u001B[0m train_loader \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mDataLoader(train_data, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m64\u001B[39m, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[1;32mC:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1355\u001B[0m, in \u001B[0;36mModule.to\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1352\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1353\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[1;32m-> 1355\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:915\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn, recurse)\u001B[0m\n\u001B[0;32m    913\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[0;32m    914\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[1;32m--> 915\u001B[0m         \u001B[43mmodule\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfn\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    917\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[0;32m    918\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[0;32m    919\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[0;32m    920\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    925\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[0;32m    926\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[1;32mC:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:942\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn, recurse)\u001B[0m\n\u001B[0;32m    938\u001B[0m \u001B[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001B[39;00m\n\u001B[0;32m    939\u001B[0m \u001B[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001B[39;00m\n\u001B[0;32m    940\u001B[0m \u001B[38;5;66;03m# `with torch.no_grad():`\u001B[39;00m\n\u001B[0;32m    941\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m--> 942\u001B[0m     param_applied \u001B[38;5;241m=\u001B[39m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparam\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    943\u001B[0m p_should_use_set_data \u001B[38;5;241m=\u001B[39m compute_should_use_set_data(param, param_applied)\n\u001B[0;32m    945\u001B[0m \u001B[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001B[39;00m\n",
      "File \u001B[1;32mC:\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1341\u001B[0m, in \u001B[0;36mModule.to.<locals>.convert\u001B[1;34m(t)\u001B[0m\n\u001B[0;32m   1334\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m convert_to_format \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m t\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m5\u001B[39m):\n\u001B[0;32m   1335\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(\n\u001B[0;32m   1336\u001B[0m             device,\n\u001B[0;32m   1337\u001B[0m             dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1338\u001B[0m             non_blocking,\n\u001B[0;32m   1339\u001B[0m             memory_format\u001B[38;5;241m=\u001B[39mconvert_to_format,\n\u001B[0;32m   1340\u001B[0m         )\n\u001B[1;32m-> 1341\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1342\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1343\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_floating_point\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_complex\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m   1344\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnon_blocking\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1345\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1346\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m   1347\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(e) \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot copy out of meta tensor; no data!\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "\u001B[1;31mRuntimeError\u001B[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "execution_count": 23
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
