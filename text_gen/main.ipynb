{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2583d756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eeb8d18e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Joke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>What did the bartender say to the jumper cable...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Don't you hate jokes about German sausage? The...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Two artists had an art contest... It ended in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Why did the chicken cross the playground? To g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>What gun do you use to hunt a moose? A moosecut!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                               Joke\n",
       "0   1  What did the bartender say to the jumper cable...\n",
       "1   2  Don't you hate jokes about German sausage? The...\n",
       "2   3  Two artists had an art contest... It ended in ...\n",
       "3   4  Why did the chicken cross the playground? To g...\n",
       "4   5   What gun do you use to hunt a moose? A moosecut!"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../stage_4_data/text_generation/data.csv') # I changed it to data.csv\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80209022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  129504\n",
      "Epoch [1/10], Training Loss: 2.3369\n",
      "Epoch [1/10], Validation Loss: 2.0856\n",
      "Epoch [2/10], Training Loss: 2.0199\n",
      "Epoch [2/10], Validation Loss: 1.9706\n",
      "Epoch [3/10], Training Loss: 1.9126\n",
      "Epoch [3/10], Validation Loss: 1.9059\n",
      "Epoch [4/10], Training Loss: 1.8466\n",
      "Epoch [4/10], Validation Loss: 1.8802\n",
      "Epoch [5/10], Training Loss: 1.7979\n",
      "Epoch [5/10], Validation Loss: 1.8412\n",
      "Epoch [6/10], Training Loss: 1.7601\n",
      "Epoch [6/10], Validation Loss: 1.8221\n",
      "Epoch [7/10], Training Loss: 1.7279\n",
      "Epoch [7/10], Validation Loss: 1.8147\n",
      "Epoch [8/10], Training Loss: 1.7025\n",
      "Epoch [8/10], Validation Loss: 1.8129\n",
      "Epoch [9/10], Training Loss: 1.6790\n",
      "Epoch [9/10], Validation Loss: 1.8035\n",
      "Epoch [10/10], Training Loss: 1.6583\n",
      "Epoch [10/10], Validation Loss: 1.8010\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        out, _ = self.rnn(x)\n",
    "        out = self.fc(out[:, -1, :]) # Get output from the last time step\n",
    "        return out\n",
    "\n",
    "# Combine all jokes into a single text\n",
    "text = \" \".join(df['Joke'].astype(str).tolist())\n",
    "chars = sorted(list(set(text)))\n",
    "char_to_int = {ch: i for i, ch in enumerate(chars)}\n",
    "int_to_char = {i: ch for i, ch in enumerate(chars)}\n",
    "\n",
    "vocab_size = len(chars)\n",
    "embedding_dim = 64 # tunable\n",
    "hidden_size = 128  # tunable\n",
    "output_size = vocab_size\n",
    "learning_rate = 0.001\n",
    "sequence_length = 100 # Length of input sequences\n",
    "epochs = 10 # Number of epochsj\n",
    "# Prepare training data\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, len(text) - sequence_length, 1):\n",
    "    seq_in = text[i:i + sequence_length]\n",
    "    seq_out = text[i + sequence_length]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "\n",
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \", n_patterns)\n",
    "split_idx = int(n_patterns * 0.8)\n",
    "\n",
    "train_dataX = dataX[:split_idx]\n",
    "train_dataY = dataY[:split_idx]\n",
    "test_dataX = dataX[split_idx:]\n",
    "test_dataY = dataY[split_idx:]\n",
    "\n",
    "X_train = torch.tensor(train_dataX, dtype=torch.long)\n",
    "Y_train = torch.tensor(train_dataY, dtype=torch.long)\n",
    "X_test = torch.tensor(test_dataX, dtype=torch.long)\n",
    "Y_test = torch.tensor(test_dataY, dtype=torch.long)\n",
    "\n",
    "# Instantiate the model\n",
    "model = RNN(vocab_size, embedding_dim, hidden_size, output_size)\n",
    "train_data = torch.utils.data.TensorDataset(X_train, Y_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "\n",
    "val_data = torch.utils.data.TensorDataset(X_test, Y_test)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=64, shuffle=False)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss_epoch = 0\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss_epoch += loss.item()\n",
    "    avg_train_loss = train_loss_epoch / len(train_loader)\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Training Loss: {avg_train_loss:.4f}')\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_X_val, batch_y_val in val_loader:\n",
    "            # batch_X_val, batch_y_val = batch_X_val.to(device), batch_y_val.to(device) # Uncomment if using GPU\n",
    "            outputs_val = model(batch_X_val)\n",
    "            loss_val = criterion(outputs_val, batch_y_val)\n",
    "            val_loss += loss_val.item()\n",
    "    \n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Validation Loss: {avg_val_loss:.4f}')\n",
    "\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2451891c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: \"What do you\"\n",
      "Generated text: \n",
      "--------------------------\n",
      "What do you call a cuitual to I was always can anterest for the race wicroan toollege Marnopant firlizan banes asked too vot own of Sairt the shower to blo meall in the find asks a turn say to the busts a Olamy \n",
      "--------------------------\n",
      "\n",
      "Generation complete.\n"
     ]
    }
   ],
   "source": [
    "# ...existing code...\n",
    "# print(\"Training complete.\")\n",
    "\n",
    "# Generate text\n",
    "model.eval()  # Set model to evaluation mode\n",
    "\n",
    "# Parameters for generation\n",
    "start_string = \"What do you\" # Or any other seed text\n",
    "num_chars_to_generate = 200\n",
    "temperature = 0.8 # Higher temperature results in more random, lower in more predictable text\n",
    "\n",
    "# Convert start string to integers\n",
    "pattern = [char_to_int[char] for char in start_string if char in char_to_int] # Filter out unknown chars\n",
    "if not pattern:\n",
    "    print(f\"Error: Seed string '{start_string}' contains no known characters or is too short after filtering.\")\n",
    "    # Fallback to a default known pattern if the seed is problematic\n",
    "    first_key = next(iter(char_to_int)) # Get the first character from our vocab\n",
    "    pattern = [char_to_int[first_key]] * min(sequence_length, 5) # Use a short sequence of a known char\n",
    "    start_string = \"\".join([int_to_char[p] for p in pattern])\n",
    "    print(f\"Using fallback seed: '{start_string}'\")\n",
    "\n",
    "\n",
    "generated_text = list(start_string) # Use a list to append characters\n",
    "\n",
    "print(f\"Seed: \\\"{start_string}\\\"\")\n",
    "print(\"Generated text: \")\n",
    "print(\"--------------------------\")\n",
    "print(start_string, end=\"\")\n",
    "\n",
    "with torch.no_grad():  # No need to track gradients\n",
    "    for i in range(num_chars_to_generate):\n",
    "        # Ensure the pattern is of the correct sequence_length\n",
    "        current_sequence_input = pattern[-sequence_length:]\n",
    "        \n",
    "        # Prepare input tensor\n",
    "        input_tensor = torch.tensor([current_sequence_input], dtype=torch.long)\n",
    "        # input_tensor = input_tensor.to(device) # Uncomment if using GPU\n",
    "\n",
    "        # Get model output (logits)\n",
    "        output = model(input_tensor)\n",
    "        \n",
    "        # Apply temperature to logits\n",
    "        output_dist = output.data.view(-1).div(temperature).exp()\n",
    "        # Sample from the distribution\n",
    "        top_i = torch.multinomial(output_dist, 1)[0]\n",
    "        \n",
    "        # Alternatively, for deterministic output (greedy):\n",
    "        # _, top_i = torch.topk(output, 1)\n",
    "        # top_i = top_i[0][0]\n",
    "\n",
    "\n",
    "        # Get the character\n",
    "        char_index = top_i.item()\n",
    "        if char_index in int_to_char:\n",
    "            char = int_to_char[char_index]\n",
    "            generated_text.append(char)\n",
    "            pattern.append(char_index)\n",
    "            print(char, end=\"\", flush=True)\n",
    "        else:\n",
    "            print(f\"\\nWarning: Predicted index {char_index} not in int_to_char map. Stopping generation.\")\n",
    "            break\n",
    "        \n",
    "        # Slide the window\n",
    "        pattern = pattern[1:] \n",
    "\n",
    "print(\"\\n--------------------------\")\n",
    "print(\"\\nGeneration complete.\")\n",
    "\n",
    "# Full generated text:\n",
    "# print(\"\".join(generated_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59db4f2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "189G",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
