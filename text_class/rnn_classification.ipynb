{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c0236cb2c248c6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T02:57:45.438722Z",
     "start_time": "2025-05-23T02:57:45.424219Z"
    }
   },
   "outputs": [],
   "source": [
    "# define import\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a258d92701d9161e",
   "metadata": {},
   "source": [
    "# Data Loading Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T02:57:47.290226Z",
     "start_time": "2025-05-23T02:57:46.242865Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 samples in train\n",
      "{'id': '2194', 'rating': 10, 'label': 1, 'text': \"One of the best records of Israel's response to the murder of Rabin.Extremely true and natural, it captured the spirit of the nation.Especially important was the response of young people to the trauma of Israel's loss and the feeling that we shall overcome.\", 'words': ['one', 'best', 'records', 'israel', 'response', 'murder', 'rabinextremely', 'true', 'natural', 'captured', 'spirit', 'nationespecially', 'important', 'response', 'young', 'people', 'trauma', 'israel', 'loss', 'feeling', 'shall', 'overcome']}\n",
      "25000 samples in test\n",
      "{'id': '804', 'rating': 1, 'label': 0, 'text': \"Where do I begin? The story was so bad, it must have been written in a high school film club! The acting was so wooden I felt sorry for the actors! One actor even reminded me of what a deer must look like when staring into a car's headlights! Another actor has this constant look of being constipated! But it was the dialog that takes the cake! <br /><br />Our hero says to his captors - all holding submachine guns - if you lay a finger on a female prisoner you will be dead. Moments later, the strongest guard, built like a truck, and the only women prisoner go at it. When our fearless leader, who has this very annoying raspy gangster voice catches wind of this transgression, he calmly walks up to the guard, while machine guns are trained on him, and in a split-second snaps this giant guy's neck like he was breaking a tooth pick! He then gets back in line while all the villains with their machine guns do absolutely nothing, but essentially yell at him!<br /><br />I could go on and on! This movie is camp gem; and if you have any sense of humor, it's guaranteed to make you laugh so hard your eyes will tear!\", 'words': ['begin', 'story', 'bad', 'must', 'written', 'high', 'school', 'film', 'club', 'acting', 'wooden', 'felt', 'sorry', 'actors', 'one', 'actor', 'even', 'reminded', 'deer', 'must', 'look', 'like', 'staring', 'car', 'headlights', 'another', 'actor', 'constant', 'look', 'constipated', 'dialog', 'takes', 'cake', 'br', 'br', 'hero', 'says', 'captors', 'holding', 'submachine', 'guns', 'lay', 'finger', 'female', 'prisoner', 'dead', 'moments', 'later', 'strongest', 'guard', 'built', 'like', 'truck', 'women', 'prisoner', 'go', 'fearless', 'leader', 'annoying', 'raspy', 'gangster', 'voice', 'catches', 'wind', 'transgression', 'calmly', 'walks', 'guard', 'machine', 'guns', 'trained', 'splitsecond', 'snaps', 'giant', 'guy', 'neck', 'like', 'breaking', 'tooth', 'pick', 'gets', 'back', 'line', 'villains', 'machine', 'guns', 'absolutely', 'nothing', 'essentially', 'yell', 'br', 'br', 'could', 'go', 'movie', 'camp', 'gem', 'sense', 'humor', 'guaranteed', 'make', 'laugh', 'hard', 'eyes', 'tear']}\n",
      "655\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import random\n",
    "\n",
    "with open(\"text_classification_train_words\", \"rb\") as f:\n",
    "    train = pickle.load(f)\n",
    "\n",
    "with open(\"text_classification_test_words\", \"rb\") as f:\n",
    "    test = pickle.load(f)\n",
    "\n",
    "print(f\"{len(train)} samples in train\")\n",
    "print(f\"{train[random.randint(0, len(train) - 1)]}\")\n",
    "print(f\"{len(test)} samples in test\")\n",
    "print(f\"{test[random.randint(0, len(test) - 1)]}\")\n",
    "print(len(train[0]['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f61adfab216d51ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T02:57:48.715556Z",
     "start_time": "2025-05-23T02:57:47.711770Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found a vocab size of 133264\n"
     ]
    }
   ],
   "source": [
    "# get vocab size\n",
    "vocab = set()\n",
    "i = 0\n",
    "for sample in train + test:\n",
    "    for word in sample['words']:\n",
    "        vocab.add(word)\n",
    "\n",
    "vocab_size = len(vocab)\n",
    "print(f\"Found a vocab size of {vocab_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422f662087b7a7aa",
   "metadata": {},
   "source": [
    "## Prepare to be embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d43f1d11acce111c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T02:57:49.209999Z",
     "start_time": "2025-05-23T02:57:49.147769Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "\n",
    "word_to_ix = {}\n",
    "\n",
    "for i, word in enumerate(vocab):\n",
    "    word_to_ix[word] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65934447f34331d2",
   "metadata": {},
   "source": [
    "##  Split Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18407271bb55f5eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T02:58:19.071722Z",
     "start_time": "2025-05-23T02:57:50.388231Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_dataset(dataset):\n",
    "    X, Y = [], []\n",
    "    for data in dataset:\n",
    "        embeddings = torch.tensor([torch.tensor([word_to_ix[word]], dtype=torch.long) for word in data['words']])\n",
    "        X.append(embeddings)\n",
    "        Y.append(data['label'])\n",
    "\n",
    "    return pad_sequence(X, batch_first=True), torch.tensor(Y)\n",
    "\n",
    "\n",
    "X_train, Y_train = create_dataset(train)\n",
    "X_test, Y_test = create_dataset(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e29aaf5421f085",
   "metadata": {},
   "source": [
    "# Prepare For Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "beccbd9c58e6f651",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T02:57:43.393955Z",
     "start_time": "2025-05-23T02:57:43.336425Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2323b225572426c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T03:08:16.272948Z",
     "start_time": "2025-05-23T03:08:16.263053Z"
    }
   },
   "outputs": [],
   "source": [
    "# define our model class\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, lstm1_hidden_size, lstm2_hidden_size, dense_hidden_size, output_size, dropout_p=0.5):\n",
    "        super(RNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.dropout_embed = nn.Dropout(dropout_p)\n",
    "\n",
    "        # First Bidirectional LSTM layer\n",
    "        # The input features for the first LSTM is the embedding dimension.\n",
    "        self.lstm1 = nn.LSTM(embedding_dim,\n",
    "                             lstm1_hidden_size,\n",
    "                             num_layers=1, # You can experiment with more layers here\n",
    "                             batch_first=True,\n",
    "                             bidirectional=True)\n",
    "        self.dropout_lstm1 = nn.Dropout(dropout_p)\n",
    "\n",
    "        # Second Bidirectional LSTM layer\n",
    "        # The input features for the second LSTM is the output of the first BiLSTM (lstm1_hidden_size * 2).\n",
    "        self.lstm2 = nn.LSTM(lstm1_hidden_size * 2, # Times 2 because of bidirectionality\n",
    "                             lstm2_hidden_size,\n",
    "                             num_layers=1, # You can experiment with more layers here\n",
    "                             batch_first=True,\n",
    "                             bidirectional=True)\n",
    "        self.dropout_lstm2 = nn.Dropout(dropout_p)\n",
    "\n",
    "        # Dense layer with ReLU (as per GeeksforGeeks)\n",
    "        # The input features for this dense layer is the output of the second BiLSTM (lstm2_hidden_size * 2).\n",
    "        self.fc1 = nn.Linear(lstm2_hidden_size * 2, dense_hidden_size) # Times 2 because of bidirectionality\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout_fc1 = nn.Dropout(dropout_p)\n",
    "\n",
    "        # Final output layer\n",
    "        self.fc2 = nn.Linear(dense_hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = self.dropout_embed(x) # Shape: (batch_size, seq_len, embedding_dim)\n",
    "\n",
    "        # First LSTM layer\n",
    "        # lstm1_out shape: (batch_size, seq_len, lstm1_hidden_size * 2)\n",
    "        # self.lstm1 also returns (hn, cn) which are the final hidden and cell states.\n",
    "        lstm1_out, _ = self.lstm1(x)\n",
    "        lstm1_out = self.dropout_lstm1(lstm1_out)\n",
    "\n",
    "        # Second LSTM layer\n",
    "        # lstm2_out shape: (batch_size, seq_len, lstm2_hidden_size * 2)\n",
    "        # hn_lstm2 shape: (num_layers*num_directions, batch_size, lstm2_hidden_size)\n",
    "        # For num_layers=1 and bidirectional=True, hn_lstm2 shape: (2, batch_size, lstm2_hidden_size)\n",
    "        _, (hn_lstm2, cn_lstm2) = self.lstm2(lstm1_out)\n",
    "        # No dropout directly on hn_lstm2 before concatenation, dropout_lstm2 was applied to the full sequence output.\n",
    "\n",
    "        # Concatenate the final forward and backward hidden states from the last LSTM layer (lstm2)\n",
    "        # hn_lstm2[-2,:,:] is the last forward hidden state.\n",
    "        # hn_lstm2[-1,:,:] is the last backward hidden state.\n",
    "        # Resulting shape: (batch_size, lstm2_hidden_size * 2)\n",
    "        hidden_combined = torch.cat((hn_lstm2[-2,:,:], hn_lstm2[-1,:,:]), dim=1)\n",
    "\n",
    "        # Dense layer with ReLU\n",
    "        out_fc1 = self.fc1(hidden_combined)\n",
    "        out_relu = self.relu(out_fc1)\n",
    "        out_dropout_fc1 = self.dropout_fc1(out_relu)\n",
    "\n",
    "        # Final output layer\n",
    "        out = self.fc2(out_dropout_fc1) # Shape: (batch_size, output_size)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14db5d657b1d5f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-23T03:08:17.360296Z",
     "start_time": "2025-05-23T03:08:17.181673Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters: 34684098\n",
      "Batch [24/391]\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 48\u001b[39m\n\u001b[32m     45\u001b[39m loss = criterion(outputs, batch_y)\n\u001b[32m     47\u001b[39m optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m48\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m optimizer.step()\n\u001b[32m     50\u001b[39m train_loss_epoch += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/coursework/ecs189/venv/lib/python3.12/site-packages/torch/_tensor.py:626\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    618\u001b[39m         Tensor.backward,\n\u001b[32m    619\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m         inputs=inputs,\n\u001b[32m    625\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/coursework/ecs189/venv/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/coursework/ecs189/venv/lib/python3.12/site-packages/torch/autograd/graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "embedding_dim = 256  # Keep as is, or tune\n",
    "# New hidden size parameters for the LSTMs and Dense layer\n",
    "lstm1_hidden_size = 128  # Tunable, G4G example might use 64\n",
    "lstm2_hidden_size = 64   # Tunable, G4G example might use 32\n",
    "dense_hidden_size = 64   # Tunable, G4G example uses 64\n",
    "dropout_rate = 0.5       # Tunable dropout rate\n",
    "\n",
    "output_size = 2 # binary classification (remains the same)\n",
    "learning_rate = 0.001 # Keep as is, or tune\n",
    "epochs = 20  # Keep as is, or tune\n",
    "\n",
    "# Instantiate the model with new parameters\n",
    "model = RNN(vocab_size,\n",
    "            embedding_dim,\n",
    "            lstm1_hidden_size,\n",
    "            lstm2_hidden_size,\n",
    "            dense_hidden_size,\n",
    "            output_size,\n",
    "            dropout_p=dropout_rate).to(device)\n",
    "\n",
    "train_data = torch.utils.data.TensorDataset(X_train, Y_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True) # Consider a smaller batch size if memory issues arise with a more complex model\n",
    "\n",
    "val_data = torch.utils.data.TensorDataset(X_test, Y_test)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, batch_size=64, shuffle=False)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Number of trainable parameters: {num_params}\")\n",
    "\n",
    "# The rest of your training loop in this cell can remain the same.\n",
    "# for epoch in range(epochs):\n",
    "#    ...\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss_epoch = 0\n",
    "    num_batches = len(train_loader)\n",
    "    for i, (batch_X, batch_y) in enumerate(train_loader):\n",
    "        batch_X, batch_y = batch_X.to(device), batch_y.to(device)\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss_epoch += loss.item()\n",
    "        print(f\"Batch [{i}/{num_batches}]\\r\", end=\"\")\n",
    "    avg_train_loss = train_loss_epoch / len(train_loader)\n",
    "    print(f'Epoch [{epoch + 1}/{epochs}], Training Loss: {avg_train_loss:.4f}\\r')\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_X_val, batch_y_val in val_loader:\n",
    "            batch_X_val, batch_y_val = batch_X_val.to(device), batch_y_val.to(device) # Uncomment if using GPU\n",
    "            outputs_val = model(batch_X_val)\n",
    "            loss_val = criterion(outputs_val, batch_y_val)\n",
    "            val_loss += loss_val.item()\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    print(f'Epoch [{epoch + 1}/{epochs}], Validation Loss: {avg_val_loss:.4f}')\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
